#! /usr/local/bin/python3
import re
import argparse
import json
import os.path
import requests
import sys
from termcolor import colored

URL_BASE = 'http://localhost:5984/wordsapi/'


def color_text(text, fc, bg=None):
    args = []
    if bg is not None:
        args.append(bg)
    return colored(text, fc, *args)

def red_text(text):
    return color_text(text, 'red')

def green_text(text):
    return color_text(text, 'green')

def get_synonyms_text(text):
    return color_text(text, 'cyan', 'on_grey')

def get_type_of_text(text):
    return color_text(text, 'magenta', 'on_white')

def blue_text(text):
    return color_text(text, 'blue')

def lookup_words(text, limit):
    text = text.strip()
    url = 'https://mpi.hugo.wang/api/words/lookup/?text={}'.format(text)
    token = get_user_token()
    headers = {'AUTHORIZATION': 'bearer {}'.format(token)}

    try:
        r = requests.get(url, headers=headers)
    except Exception as e:
        print('requests get error: {}'.format(e.__class__.__name__))
        return

    result = json.loads(r.text)
    word_list = []
    i = 0
    for item in result['data']:
        i += 1
        word = red_text(item[0])
        pron = green_text(item[2])
        defines = item[1]
        print('{} [{}] - {}'.format(word, pron, defines))
        if i >= limit:
            break

def get_chinese_defines(word):
    word = word.strip()
    url = 'https://mpi.hugo.wang/api/words/cn/?w={}'.format(word)
    token = get_user_token()
    headers = {'AUTHORIZATION': 'bearer {}'.format(token)}
    try:
        r = requests.get(url, headers=headers)
    except Exception as e:
        print('requests get error: {}'.format(e.__class__.__name__))
        return False
    result = json.loads(r.text)
    if 'cts' not in result or not result['cts']:
        return False
    word = result['word']
    pron = result['pron']
    print('{} [{}]'.format(red_text(word), green_text(pron)))
    for type_ in result['cts']:
        define = result['cts'][type_]
        print('{}. {}'.format(blue_text(type_), define))
    return True

def get_user_token():
    dir_conf = os.path.join(os.path.expanduser('~'), '.config', 'wd')
    if not os.path.exists(dir_conf):
        print('dir {} not found'.format(dir_conf))
        exit(1)
    file_token = os.path.join(dir_conf, 'token.txt')
    if not os.path.exists(file_token):
        print('file {} not found'.format(file_token))
        exit(1)
    with open(file_token) as f:
        return f.read().strip()


def get_en_defines(args, word):
    try:
        r = requests.get(URL_BASE + word)
    except Exception as e:
        print('requests get error: {}'.format(e.__class__.__name__))
        return

    if r.status_code == 404:
        print('no en define found for {}'.format(word))
        return
    elif r.status_code != 200:
        print(r)
        return

    result = json.loads(r.text)
    if args.raw:
        print(json.dumps(result, indent=4))
        return

    for item in result.get("results", []):
        pos = item.get("partOfSpeech") or ''
        if pos == '':
            pos = 'un'
        if pos == 'noun':
            pos = 'n'
        elif pos.startswith('v'):
            pass
        else:
            pos = pos[:3]
        info = red_text(pos + ". ")
        info += "{}".format(green_text(item.get("definition", "")))

        if "examples" in item:
            for example in item["examples"]:
                info += "\n"
                info += blue_text(example)
        if "typeOf" in item:
            info += "\n"
            info += red_text("is type of. ")
            info += " ".join([get_type_of_text(x) for x in item["typeOf"]])
        if "synonyms" in item:
            info += "\n"
            info += red_text("synonyms. ")
            info += " ".join([get_synonyms_text(x) for x in item["synonyms"]])
        elif 'similarTo' in item:
            info += "\n"
            info += red_text("similar to. ")
            info += " ".join([get_synonyms_text(x) for x in item["similarTo"]])
        if 'pertainsTo' in item:
            info += "\n"
            info += red_text("pertains to. ")
            info += " ".join([get_synonyms_text(x) for x in item["pertainsTo"]])
        if "derivation" in item:
            info += "\n"
            info += red_text("derivation. ")
            info += " ".join([get_type_of_text(x) for x in item["derivation"]])
        print(info + "\n")


def main(args):
    limit = args.limit
    word = args.word.lower().strip()
    if not re.search(r'^[a-zA-Z]+$', word) or args.lookup:
        lookup_words(word, limit)
        return

    get_en_defines(args, word)
    if not get_chinese_defines(word):
        lookup_words(word, limit)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Word Define')
    parser.add_argument('--raw', action='store_true')
    parser.add_argument('-l', '--lookup', action='store_true')
    parser.add_argument('-n', '--limit', type=int, default=100)
    parser.add_argument('word', help='word to lookup')
    args = parser.parse_args()
    main(args)
